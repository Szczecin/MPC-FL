# 联邦视觉系统原理与展望
## 1.横向联邦学习(Horizontal Federated Learning) 
传统的以表格的方式查看数据库，横向的按行 对数据分组，每行数据包含的数据特征相同 各个参与者拥有的数据特征相同（包括数据标签），数据indices/ID不同。<br>
 - 参与者之间不需要交换信息；有FedAvg算法；<br>
 - 对深度学习（深度神经网络）有很好的支持。<br><br>

1）各参与者(Participant)向中间协调方（Coordinator）提交所用的加密梯度（Send encrypted gradients）；<br>
2）协调方对数据进行安全聚合（Secure aggregation）；<br>
3）协调方将聚合更新后的数据模型输出给各个应得的参与方（Sending back model updates）；<br>
4）各个参与方分析应用得到的模型对已有的本地模型更新（Updating models）<br><br>

## 2.联邦视觉系统架构
1）通过用户在本地端对图像的标注，将标注结果提交给本地联邦学习客户端；<br>
2）客户端对本地资源进行监控管理，收集到足够资源后导入生成本地模型，并提交给联邦学习服务端；<br>
3）服务器端收到各客户端输入的各模型数据后开始任务调度，进行联邦学习；<br>
4）调度NGINX从模型仓库中选择模型匹配学习并对模型进行聚合；<br>
5）将学习后的模型反馈给客户端，对客户端本地模型进行更新。<br><br>

## 3.图像标注模块
• 用户在本地设备中直接标注数据 <br>
• 本地数据不上传，标注完成后保留在本地 作为本地模型的训练数据 <br>
• 标注完成后，客户端自动加入联邦，等待 进行训练 <br>
• 当有两台设备进入到待训练状态时，开始 进行联邦学习训练模式<br><br>

## 4.联邦视觉系统的五种状态
用户在本地进行数据标注，进入创建态（状态1） <br>
• 标注完成后，检测运行所需要的硬件资源、网络通 信条件，进行可运行态（状态2） <br>
• 服务端下发训练指令，进入训练状态（状态3） <br>
• 联邦学习的训练过程是一个不断在客户端和服务端 进行交互迭代的过程，直到运行结束（状态5） <br>
• 在训练过程中，遇到硬件、网络等故障时，将自动 进入堵塞进行等待（状态4）<br><br>

## 5.目标检测算法
1）从给予的图片数据中，提取多层残余层，再进行残余层的叠加；<br>
2）记叠加后的残余层为α，从叠加后的残余层α里生成长宽1/2的残余层β，从残余层β中提取长宽为1/2的探测层α，多份探测层叠加可以初步还原原图片数据，不清晰；<br>
3）对提取出的探测层α进行上采样技术，长宽放大2倍并提取采样层，采样层与残余层β进行串联叠加后得到新的探测层β，多份探测层叠加可以初步还原原图片数据，比前一步还原后结果清晰；<br>
4）对提取出的探测层β进行上采样技术，长宽放大2倍并提取采样层，采样层与残余层α进行串联叠加后得到新的探测层γ，多份探测层叠加可以初步还原原图片数据，比前一步还原后结果清晰；<br>
5）实际操作中是将原图像数据数据划分为t层，即将原图像数据分为M1^(t-1)（可在本地还原出原图片数据）与M1^t，两者的差为R1^t，实际上就是将原图像数据进行了一次压缩，在从本地传输给服务器，而压缩后的R1^t是t层数据相与的结果；<br>
6）服务器接受到两组及以上的数据后，对数据进行分层聚合，操作是将得到的R1^t与R2^t进行逻辑乘，能够形成新的M^t<br><br>

### YOLOv3的方法可以被总结为如下步骤：
给定一张图片，比如图4中的火焰图片，它首先将这张图片分割成s x s的网格，每个网格都被用于使用其中间图像来检测目标物体（在图4中的蓝色方块网格被用于去检测火焰）。<br>
对于每个网格来说，这个算法执行如下的计算：<br>

预测B边界框的位置。每个边界框被描述为一个四元组（x,y,w,h），其中（x,y）是这个框的中心坐标，（w,h）分别代表这个边界框的宽度和长度。<br>
估计被预测出来的所有的B边界框的置信度。这个置信度由两部分构成：1）是否一个边界框包含了目标物体，和2）这个框的边界有多精确。第一部分可以被描述为p(obj)。<br>
如果这个边界框包含了目标物体，那么p(obj)=1。这个被预测出来的边界框的精度可以通过其与真实边界框的的交并比（IOU）值计算出来。<br>
对于所有C个类别，计算每一个类别的条件概率，p(c_ij | obj) $\in$ [0,1]<br><br>

## 6.mAP定义及相关概念
	• mAP: mean Average Precision, 即各类别AP的平均值<br>
	• AP: PR曲线下面积，后文会详细讲解<br>
	• PR曲线: Precision-Recall曲线<br>
	• Precision: TP / (TP + FP)<br>
	• Recall: TP / (TP + FN)<br>
	• TP: IoU>0.5的检测框数量（同一Ground Truth只计算一次）<br>
	• FP: IoU<=0.5的检测框，或者是检测到同一个GT的多余检测框的数量<br>
	• FN: 没有检测到的GT的数量<br><br>

### mAP的具体计算

由前面定义，我们可以知道，要计算mAP必须先绘出各类别PR曲线，计算出AP。而如何采样PR曲线，VOC采用过两种不同方法。<br>
参见：The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Development Kit <br>
在VOC2010以前，只需要选取当Recall >= 0, 0.1, 0.2, ..., 1共11个点时的Precision最大值，然后AP就是这11个Precision的平均值。<br>
在VOC2010及以后，需要针对每一个不同的Recall值（包括0和1），选取其大于等于这些Recall值时的Precision最大值，然后计算PR曲线下面积作为AP值。<br><br>

## 7.基于联邦学习的模型共建机制
机制要点<br>
• 充分利用各方样本数据 <br>
• 有效衡量各方样本数据贡献 <br>
• 基于样本贡献的价值分配<br><br>
