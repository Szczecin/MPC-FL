## 1.联邦学习 （Federated Machine Learning）的研究进展 
### • 系统效率 
• 模型压缩 Compression [KMY16] <br>
• 算法优化 Optimization algorithms [KMR16] <br>
• 参与方选取 Client selection [NY18] <br>
• 边缘计算 Resource constraint, IoT, Edge computing [WTS18] <br><br>
### • 模型效果 
• 数据分布不均匀 Data distribution and selection [ZLL18] <br>
• 个性化 Personalization [SCS18] <br><br>
### • 数据安全

## 2.Secure Aggregation [BIK+17] 
• 本地训练 Local training <br>
• 秘密共享 Secret share aggregated update <br>
• 稳定性 Robust to vanishing clients <br>
• 无个人梯度信息泄露 Individual gradient not disclosed <br>
• 半诚实假设 honest-but-curious setting, server does not collude with users<br>

## 3.纵向联邦学习 Vertical Federated Learning 
```
ID X1 X2 X3 
U1 9 80 600 
U2 4 50 550 
U3 2 35 520 
U4 10 100 600 
U5 5 75 600 
U6 5 75 520 
U7 8 80 600 
Retail A Data 
```
```
ID X4 X5 Y 
U1 6000 600 No 
U2 5500 500 Yes 
U3 7200 500 Yes 
U4 6000 600 No 
U8 6000 600 No 
U9 4520 500 Yes 
U10 6000 600 No 
Bank B Data 
```

目标: ➢ A方 和 B 方 联合建立模型 <br>
假设： ➢ 只有一方有标签 Y ➢ 两方均不暴露数据 <br>
挑战: ➢ 只有X的一方没有办法建立模型 ➢ 双方不能交换共享数据 <br>
预期： ➢ 双方均获得数据保护 ➢ 模型无损失 （LOSSLESS）<br><br>

## 4.保护隐私的机器学习Privacy-Preserving Machine Learning 
半诚实(Honest-but-curious) VS 恶意(Malicious) <br>
零知识(Zero knowledge) VS 一些知识(Some knowledge) <br>
恶意中心(Adversarial Server) VS 恶意数据节点(Adversarial Client) <br><br>

## 5.多方安全计算 (MPC) 
• 保证信息层面的数据安全 <br>
• 零知识证明 zero knowledge <br>
• 需要多方参与 <br><br>
### • 缺点： 
• 大量信息传输 <br>
• 降低数据安全要求可以提高效率<br><br>

## 6.SecureML [MZ17] 
• 隐私保护下的机器学习 Privacy-preserving machine learning for linear regression, logistic regression and neural network training <br>
• 秘密共享，混淆电路，不经意传输 Combine secret sharing, garbled circuits and oblivious transfer <br>
• 需要两方计算 Learn via two untrusted, but non-colluding servers <br>
• Computationally secure, but expensive<br><br>

## 7.同态加密 Homomorphic Encryption 
• 全同态或者半同态 Full Homomorphic Encryption and Partial Homomorphic Encryption <br>
• 数据层面的信息保护 Data-level information protection <br><br>
### Paillier 半同态加密 Partially homomorphic encryption 
Addition : [[u]] + [[v]] = [[u+v]] <br>
Scalar multiplication: n[[u]] = [[nu]] <br>
• For public key pk = n, the encoded form of m ∈ {0, . . . , n − 1} is Encode(m) = r^n (1 + n)^m mod n^2 r is random selected from {0, . . . , n − 1}. <br>
• For float q = (s, e) , encrypt [[q]] = ([[s]], e) , here q = sβe ，is base-β exponential representation.<br><br>

## 8.同态加密在机器学习上应用 Apply HE to Machine Learning  
① 多项式近似 Polynomial approximation for logarithm function <br>
②加密计算 Encrypted computation for each term in the polynomial function <br><br>

## 9.隐私保护的深度学习推断
### CryptoNet 
• Leveled homomorphic encryption <br>
• Privately evaluate neural network <br><br>

### DeepSecure
• Yao’s GC<br><br>

### MiniONN 
• Offline lattice-based AHE <br>
• Online GC and secret-sharing<br><br>

### Chameleon 
• 3-server model <br>
• trusted third-party dealers<br><br>

### GAZELLE [GVC18] 
• Lattice-based packed addictive HE for linear layer <br>
• Garbled Circuit for non-linear layer <br>
• Three orders of magnitude faster than CryptoNets [DBL+16]<br><br>

## 10.安全定义 Security Definition 
• All parties are honest-but-curious. <br>
• We assume a threat model with a semi-honest adversary who can corrupt at most one of the two data clients. <br>
• For a protocol P performing (OA ,OB )=P(IA ,IB ), where OA and OB are party A and B's output and IA and IB are their inputs, <br>
P is secure against A if there exists an infinite number of (I'B ,O'B ) pairs such that (OA ,O'B )=P(IA ,I'B ). <br>
• A practical solution to control information disclosure. <br><br>

## 11.一堆的数学表达，好难看啊

## 12.联邦学习是可以去掉第三方，产生两方方案的

## 13.真 · 一堆的数学表达，好难看啊QAQ

## 14.安全性分析 
### • Security against third-party C 
• All C learns are the masked gradients and the randomness and secrecy of the masked matrix are guaranteed <br>
### • Security against each other 
• Party A learns its gradient at each step, but this is not enough for A to learn any information about B <br>
• Inability of solving n equations with more than n unknowns <br>
### • Security in the semi-honest setting

## 15.还是一堆数学分析，真的有人会仔细看吗？

## 16.系统原理 Architecture 
Step 1 Party A and B send public keys to each other <br>
Step 2 Parties compute, encrypt and exchange intermediate results <br>
Step 3 Parties compute encrypted gradients, add masks and send to each other <br>
Step 4 Parties decrypt gradients and exchange, unmask and update model locally<br><br>

## 17.数学分析……

## 18.模型推断
Step 1 Party B computes and sends intermediate results to A<br>
Step 2 Party A computes encrypted result, adds mask and send back to B<br>
Step 3 Party B decrypts masked result and sends back to A<br>
Step 4 Party A unmasks results, predicts, and sends to B<br><br>

## 19.数学表达

## 20.优势 Advantages
• 没有泄露原始数据 No exposure of raw data <br>
• 没有泄露原始数据的加密形式 No exposure of encrypted raw data <br>
• 没有第三方 No Third Party <br>
• 模型几乎无损失 Almost lossless accuracy <br><br>

## 21.延伸性 Scalability
• 加密数据传输和加密运算是最大影响因素; <br>
• 数据传输与数据量成正比; <br>
• 加密运算代价与模型复杂度（参数量）成正比；<br><br>

## 22.Feature-based Heterogeneous FTL （HFTL）
Step 1 : Private transfer learning<br>
Step 2 : Private federated learning<br>
Step 3 : Private model integration<br>
Step 4 : Private model inference<br><br>

## 23.开发流程 Basic Process of Developing a Federated AI Algorithm 
1.选择一个机器学习算法，设计多方安全计算协议 <br>
2.定义多方交互的数据变量<br>
3.构建算法执行工作流 <br>
4.基于EggRoll & Federation Api 实现算法工作流中各个功能组件<br><br>

## 24.目前 FATE 项目中算法&案例  
### • Secure Intersection for Sample Alignment 
### • Vertical-Split Feature Space Federated Learning 
• Secure Logistic Regression <br>
• Secure Boosting Tree <br>
• Secure DNN/CNN（Coming Soon） <br><br>
### • Horizontal-Split Sample Space Federated Learning 
• Secure Logistic Regression <br>
• Secure Boosting Tree（Coming Soon） <br>
• Secure DNN/CNN（Coming Soon） <br><br>
### • Secure Federated Transfer Learning

## 25.WorkFlow Example 
### • 工作流
• 定义联邦算法组件执行工作流 <br><br>
### • 组件
• 参数初始化组件<br>
• 数据加载和转换组件 <br>
• 训练、预测组件 <br>
• 评估组件 <br>
• 模型保存组件<br><br>

## 26.FederatedML Functions Example 
### • 纵向LR梯度一方分布式计算 
• 定义梯度和损失计算公式 <br>
• 设计算法并行方式 <br>
• 通过Eggroll API 实现分布式梯度聚合和损失计算<br><br>

## 27.Federation API Example 
### • 纵向LR梯度两方联合 
• 定义算法交互信息-梯度（json 配置文件，数据源和目的地） <br>
• 生成梯度交互信息唯一标识符 <br>
• Federation API 完成梯度交互信息的收发<br><br>
